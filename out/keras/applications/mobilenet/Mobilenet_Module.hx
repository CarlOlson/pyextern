/* This file is generated, do not edit! */
package keras.applications.mobilenet;
@:pythonImport("keras.applications.mobilenet") extern class Mobilenet_Module {
	static public var BASE_WEIGHT_PATH : Dynamic;
	/**
		`Input()` is used to instantiate a Keras tensor.
		
		A Keras tensor is a tensor object from the underlying backend
		(Theano or TensorFlow), which we augment with certain
		attributes that allow us to build a Keras model
		just by knowing the inputs and outputs of the model.
		
		For instance, if a, b and c are Keras tensors,
		it becomes possible to do:
		`model = Model(input=[a, b], output=c)`
		
		The added Keras attributes are:
		    ._keras_shape: Integer shape tuple propagated
		        via Keras-side shape inference.
		    ._keras_history: Last layer applied to the tensor.
		        the entire layer graph is retrievable from that layer,
		        recursively.
		
		# Arguments
		    shape: A shape tuple (integer), not including the batch size.
		        For instance, `shape=(32,)` indicates that the expected input
		        will be batches of 32-dimensional vectors.
		    batch_shape: A shape tuple (integer), including the batch size.
		        For instance, `batch_shape=(10, 32)` indicates that
		        the expected input will be batches of 10 32-dimensional vectors.
		        `batch_shape=(None, 32)` indicates batches of an arbitrary number
		        of 32-dimensional vectors.
		    name: An optional name string for the layer.
		        Should be unique in a model (do not reuse the same name twice).
		        It will be autogenerated if it isn't provided.
		    dtype: The data type expected by the input, as a string
		        (`float32`, `float64`, `int32`...)
		    sparse: A boolean specifying whether the placeholder
		        to be created is sparse.
		    tensor: Optional existing tensor to wrap into the `Input` layer.
		        If set, the layer will not create a placeholder tensor.
		
		# Returns
		    A tensor.
		
		# Example
		
		    ```python
		    # this is a logistic regression in Keras
		    x = Input(shape=(32,))
		    y = Dense(16, activation='softmax')(x)
		    model = Model(x, y)
		    ```
	**/
	static public function Input(?shape:Dynamic, ?batch_shape:Dynamic, ?name:Dynamic, ?dtype:Dynamic, ?sparse:Dynamic, ?tensor:Dynamic):Dynamic;
	/**
		Instantiates the MobileNet architecture.
		
		Note that only TensorFlow is supported for now,
		therefore it only works with the data format
		`image_data_format='channels_last'` in your Keras config
		at `~/.keras/keras.json`.
		
		To load a MobileNet model via `load_model`, import the custom
		objects `relu6` and `DepthwiseConv2D` and pass them to the
		`custom_objects` parameter.
		E.g.
		model = load_model('mobilenet.h5', custom_objects={
		                   'relu6': mobilenet.relu6,
		                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})
		
		# Arguments
		    input_shape: optional shape tuple, only to be specified
		        if `include_top` is False (otherwise the input shape
		        has to be `(224, 224, 3)` (with `channels_last` data format)
		        or (3, 224, 224) (with `channels_first` data format).
		        It should have exactly 3 inputs channels,
		        and width and height should be no smaller than 32.
		        E.g. `(200, 200, 3)` would be one valid value.
		    alpha: controls the width of the network.
		        - If `alpha` < 1.0, proportionally decreases the number
		            of filters in each layer.
		        - If `alpha` > 1.0, proportionally increases the number
		            of filters in each layer.
		        - If `alpha` = 1, default number of filters from the paper
		             are used at each layer.
		    depth_multiplier: depth multiplier for depthwise convolution
		        (also called the resolution multiplier)
		    dropout: dropout rate
		    include_top: whether to include the fully-connected
		        layer at the top of the network.
		    weights: `None` (random initialization) or
		        `imagenet` (ImageNet weights)
		    input_tensor: optional Keras tensor (i.e. output of
		        `layers.Input()`)
		        to use as image input for the model.
		    pooling: Optional pooling mode for feature extraction
		        when `include_top` is `False`.
		        - `None` means that the output of the model
		            will be the 4D tensor output of the
		            last convolutional layer.
		        - `avg` means that global average pooling
		            will be applied to the output of the
		            last convolutional layer, and thus
		            the output of the model will be a
		            2D tensor.
		        - `max` means that global max pooling will
		            be applied.
		    classes: optional number of classes to classify images
		        into, only to be specified if `include_top` is True, and
		        if no `weights` argument is specified.
		
		# Returns
		    A Keras model instance.
		
		# Raises
		    ValueError: in case of invalid argument for `weights`,
		        or invalid input shape.
		    RuntimeError: If attempting to run this model with a
		        backend that does not support separable convolutions.
	**/
	static public function MobileNet(?input_shape:Dynamic, ?alpha:Dynamic, ?depth_multiplier:Dynamic, ?dropout:Dynamic, ?include_top:Dynamic, ?weights:Dynamic, ?input_tensor:Dynamic, ?pooling:Dynamic, ?classes:Dynamic):Dynamic;
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __spec__ : Dynamic;
	/**
		Adds an initial convolution layer (with batch normalization and relu6).
		
		# Arguments
		    inputs: Input tensor of shape `(rows, cols, 3)`
		        (with `channels_last` data format) or
		        (3, rows, cols) (with `channels_first` data format).
		        It should have exactly 3 inputs channels,
		        and width and height should be no smaller than 32.
		        E.g. `(224, 224, 3)` would be one valid value.
		    filters: Integer, the dimensionality of the output space
		        (i.e. the number output of filters in the convolution).
		    alpha: controls the width of the network.
		        - If `alpha` < 1.0, proportionally decreases the number
		            of filters in each layer.
		        - If `alpha` > 1.0, proportionally increases the number
		            of filters in each layer.
		        - If `alpha` = 1, default number of filters from the paper
		             are used at each layer.
		    kernel: An integer or tuple/list of 2 integers, specifying the
		        width and height of the 2D convolution window.
		        Can be a single integer to specify the same value for
		        all spatial dimensions.
		    strides: An integer or tuple/list of 2 integers,
		        specifying the strides of the convolution along the width and height.
		        Can be a single integer to specify the same value for
		        all spatial dimensions.
		        Specifying any stride value != 1 is incompatible with specifying
		        any `dilation_rate` value != 1.
		
		# Input shape
		    4D tensor with shape:
		    `(samples, channels, rows, cols)` if data_format='channels_first'
		    or 4D tensor with shape:
		    `(samples, rows, cols, channels)` if data_format='channels_last'.
		
		# Output shape
		    4D tensor with shape:
		    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'
		    or 4D tensor with shape:
		    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.
		    `rows` and `cols` values might have changed due to stride.
		
		# Returns
		    Output tensor of block.
	**/
	static public function _conv_block(inputs:Dynamic, filters:Dynamic, alpha:Dynamic, ?kernel:Dynamic, ?strides:Dynamic):Dynamic;
	/**
		Adds a depthwise convolution block.
		
		A depthwise convolution block consists of a depthwise conv,
		batch normalization, relu6, pointwise convolution,
		batch normalization and relu6 activation.
		
		# Arguments
		    inputs: Input tensor of shape `(rows, cols, channels)`
		        (with `channels_last` data format) or
		        (channels, rows, cols) (with `channels_first` data format).
		    pointwise_conv_filters: Integer, the dimensionality of the output space
		        (i.e. the number output of filters in the pointwise convolution).
		    alpha: controls the width of the network.
		        - If `alpha` < 1.0, proportionally decreases the number
		            of filters in each layer.
		        - If `alpha` > 1.0, proportionally increases the number
		            of filters in each layer.
		        - If `alpha` = 1, default number of filters from the paper
		             are used at each layer.
		    depth_multiplier: The number of depthwise convolution output channels
		        for each input channel.
		        The total number of depthwise convolution output
		        channels will be equal to `filters_in * depth_multiplier`.
		    strides: An integer or tuple/list of 2 integers,
		        specifying the strides of the convolution along the width and height.
		        Can be a single integer to specify the same value for
		        all spatial dimensions.
		        Specifying any stride value != 1 is incompatible with specifying
		        any `dilation_rate` value != 1.
		    block_id: Integer, a unique identification designating the block number.
		
		# Input shape
		    4D tensor with shape:
		    `(batch, channels, rows, cols)` if data_format='channels_first'
		    or 4D tensor with shape:
		    `(batch, rows, cols, channels)` if data_format='channels_last'.
		
		# Output shape
		    4D tensor with shape:
		    `(batch, filters, new_rows, new_cols)` if data_format='channels_first'
		    or 4D tensor with shape:
		    `(batch, new_rows, new_cols, filters)` if data_format='channels_last'.
		    `rows` and `cols` values might have changed due to stride.
		
		# Returns
		    Output tensor of block.
	**/
	static public function _depthwise_conv_block(inputs:Dynamic, pointwise_conv_filters:Dynamic, alpha:Dynamic, ?depth_multiplier:Dynamic, ?strides:Dynamic, ?block_id:Dynamic):Dynamic;
	/**
		Internal utility to compute/validate an ImageNet model's input shape.
		
		# Arguments
		    input_shape: either None (will return the default network input shape),
		        or a user-provided shape to be validated.
		    default_size: default input width/height for the model.
		    min_size: minimum input width/height accepted by the model.
		    data_format: image data format to use.
		    include_top: whether the model is expected to
		        be linked to a classifier via a Flatten layer.
		
		# Returns
		    An integer shape tuple (may include None entries).
		
		# Raises
		    ValueError: in case of invalid argument values.
	**/
	static public function _obtain_input_shape(input_shape:Dynamic, default_size:Dynamic, min_size:Dynamic, data_format:Dynamic, include_top:Dynamic):Dynamic;
	static public var absolute_import : Dynamic;
	/**
		Decodes the prediction of an ImageNet model.
		
		# Arguments
		    preds: Numpy tensor encoding a batch of predictions.
		    top: integer, how many top-guesses to return.
		
		# Returns
		    A list of lists of top class prediction tuples
		    `(class_name, class_description, score)`.
		    One list of tuples per sample in batch input.
		
		# Raises
		    ValueError: in case of invalid shape of the `pred` array
		        (must be 2D).
	**/
	static public function decode_predictions(preds:Dynamic, ?top:Dynamic):Dynamic;
	static public var division : Dynamic;
	/**
		Downloads a file from a URL if it not already in the cache.
		
		By default the file at the url `origin` is downloaded to the
		cache_dir `~/.keras`, placed in the cache_subdir `datasets`,
		and given the filename `fname`. The final location of a file
		`example.txt` would therefore be `~/.keras/datasets/example.txt`.
		
		Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.
		Passing a hash will verify the file after download. The command line
		programs `shasum` and `sha256sum` can compute the hash.
		
		# Arguments
		    fname: Name of the file. If an absolute path `/path/to/file.txt` is
		        specified the file will be saved at that location.
		    origin: Original URL of the file.
		    untar: Deprecated in favor of 'extract'.
		        boolean, whether the file should be decompressed
		    md5_hash: Deprecated in favor of 'file_hash'.
		        md5 hash of the file for verification
		    file_hash: The expected hash string of the file after download.
		        The sha256 and md5 hash algorithms are both supported.
		    cache_subdir: Subdirectory under the Keras cache dir where the file is
		        saved. If an absolute path `/path/to/folder` is
		        specified the file will be saved at that location.
		    hash_algorithm: Select the hash algorithm to verify the file.
		        options are 'md5', 'sha256', and 'auto'.
		        The default 'auto' detects the hash algorithm in use.
		    extract: True tries extracting the file as an Archive, like tar or zip.
		    archive_format: Archive format to try for extracting the file.
		        Options are 'auto', 'tar', 'zip', and None.
		        'tar' includes tar, tar.gz, and tar.bz files.
		        The default 'auto' is ['tar', 'zip'].
		        None or an empty list will return no matches found.
		    cache_dir: Location to store cached files, when None it
		        defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).
		
		# Returns
		    Path to the downloaded file
	**/
	static public function get_file(fname:Dynamic, origin:Dynamic, ?untar:Dynamic, ?md5_hash:Dynamic, ?file_hash:Dynamic, ?cache_subdir:Dynamic, ?hash_algorithm:Dynamic, ?extract:Dynamic, ?archive_format:Dynamic, ?cache_dir:Dynamic):Dynamic;
	/**
		Returns the list of input tensors necessary to compute `tensor`.
		
		Output will always be a list of tensors
		(potentially with 1 element).
		
		# Arguments
		    tensor: The tensor to start from.
		    layer: Origin layer of the tensor. Will be
		        determined via tensor._keras_history if not provided.
		    node_index: Origin node index of the tensor.
		
		# Returns
		    List of input tensors.
	**/
	static public function get_source_inputs(tensor:Dynamic, ?layer:Dynamic, ?node_index:Dynamic):Dynamic;
	static public function preprocess_input(x:Dynamic):Dynamic;
	static public var print_function : Dynamic;
	static public function relu6(x:Dynamic):Dynamic;
}