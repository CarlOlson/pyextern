/* This file is generated, do not edit! */
package pandas.io.sql;
@:pythonImport("pandas.io.sql") extern class Sql_Module {
	static public var _MYSQL_WARNING : Dynamic;
	static public var _SAFE_NAMES_WARNING : Dynamic;
	static public var _SQLALCHEMY_INSTALLED : Dynamic;
	static public var _SQL_GET_IDENTIFIER : Dynamic;
	static public var _SQL_TYPES : Dynamic;
	static public var _SQL_WILDCARD : Dynamic;
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __spec__ : Dynamic;
	/**
		convert sql and params args to DBAPI2.0 compliant format
	**/
	static public function _convert_params(sql:Dynamic, params:Dynamic):Dynamic;
	/**
		Returns a SQLAlchemy engine from a URI (if con is a string)
		else it just return con without modifying it
	**/
	static public function _engine_builder(con:Dynamic):Dynamic;
	static public function _get_unicode_name(name:Dynamic):Dynamic;
	static public function _get_valid_mysql_name(name:Dynamic):Dynamic;
	static public function _get_valid_sqlite_name(name:Dynamic):Dynamic;
	static public function _handle_date_column(col:Dynamic, ?format:Dynamic):Dynamic;
	static public function _is_sqlalchemy_connectable(con:Dynamic):Dynamic;
	/**
		Force non-datetime columns to be read as such.
		Supports both string formatted and integer timestamp columns
	**/
	static public function _parse_date_columns(data_frame:Dynamic, parse_dates:Dynamic):Dynamic;
	static public function _safe_fetch(cur:Dynamic):Dynamic;
	/**
		Wrap result set of query in a DataFrame 
	**/
	static public function _wrap_result(data:Dynamic, columns:Dynamic, ?index_col:Dynamic, ?coerce_float:Dynamic, ?parse_dates:Dynamic):Dynamic;
	/**
		@contextmanager decorator.
		
		Typical usage:
		
		    @contextmanager
		    def some_generator(<arguments>):
		        <setup>
		        try:
		            yield <value>
		        finally:
		            <cleanup>
		
		This makes this:
		
		    with some_generator(<arguments>) as <variable>:
		        <body>
		
		equivalent to this:
		
		    <setup>
		    try:
		        <variable> = <value>
		        <body>
		    finally:
		        <cleanup>
	**/
	static public function contextmanager(func:Dynamic):Dynamic;
	static public var division : Dynamic;
	/**
		Execute the given SQL query using the provided connection object.
		
		Parameters
		----------
		sql : string
		    Query to be executed
		con : SQLAlchemy connectable(engine/connection) or sqlite3 DBAPI2 connection
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		cur : deprecated, cursor is obtained from connection, default: None
		params : list or tuple, optional, default: None
		    List of parameters to pass to execute method.
		
		Returns
		-------
		Results Iterable
	**/
	static public function execute(sql:Dynamic, con:Dynamic, ?cur:Dynamic, ?params:Dynamic):Dynamic;
	/**
		DEPRECATED - use read_sql
		
		
		Read SQL query or database table into a DataFrame.
		
		Parameters
		----------
		sql : string SQL query or SQLAlchemy Selectable (select or text object)
		    to be executed, or database table name.
		con : SQLAlchemy connectable(engine/connection) or database string URI
		    or DBAPI2 connection (fallback mode)
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		index_col : string or list of strings, optional, default: None
		    Column(s) to set as index(MultiIndex)
		coerce_float : boolean, default True
		    Attempt to convert values to non-string, non-numeric objects (like
		    decimal.Decimal) to floating point, useful for SQL result sets
		params : list, tuple or dict, optional, default: None
		    List of parameters to pass to execute method.  The syntax used
		    to pass parameters is database driver dependent. Check your
		    database driver documentation for which of the five syntax styles,
		    described in PEP 249's paramstyle, is supported.
		    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}
		parse_dates : list or dict, default: None
		    - List of column names to parse as dates
		    - Dict of ``{column_name: format string}`` where format string is
		      strftime compatible in case of parsing string times or is one of
		      (D, s, ns, ms, us) in case of parsing integer timestamps
		    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
		      to the keyword arguments of :func:`pandas.to_datetime`
		      Especially useful with databases without native Datetime support,
		      such as SQLite
		columns : list, default: None
		    List of column names to select from sql table (only used when reading
		    a table).
		chunksize : int, default None
		    If specified, return an iterator where `chunksize` is the
		    number of rows to include in each chunk.
		
		Returns
		-------
		DataFrame
		
		Notes
		-----
		This function is a convenience wrapper around ``read_sql_table`` and
		``read_sql_query`` (and for backward compatibility) and will delegate
		to the specific function depending on the provided input (database
		table name or sql query).  The delegated function might have more specific
		notes about their functionality not listed here.
		
		See also
		--------
		read_sql_table : Read SQL database table into a DataFrame
		read_sql_query : Read SQL query into a DataFrame
	**/
	static public function frame_query(?args:python.VarArgs<Dynamic>, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Get the SQL db table schema for the given frame.
		
		Parameters
		----------
		frame : DataFrame
		name : string
		    name of SQL table
		flavor : {'sqlite', 'mysql'}, default 'sqlite'
		    The flavor of SQL to use. Ignored when using SQLAlchemy connectable.
		    'mysql' is deprecated and will be removed in future versions, but it
		    will be further supported through SQLAlchemy engines.
		keys : string or sequence, default: None
		    columns to use a primary key
		con: an open SQL database connection object or a SQLAlchemy connectable
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library, default: None
		    If a DBAPI2 object, only sqlite3 is supported.
		dtype : dict of column name to SQL type, default None
		    Optional specifying the datatype for columns. The SQL type should
		    be a SQLAlchemy type, or a string for sqlite3 fallback connection.
	**/
	static public function get_schema(frame:Dynamic, name:Dynamic, ?flavor:Dynamic, ?keys:Dynamic, ?con:Dynamic, ?dtype:Dynamic):Dynamic;
	/**
		Check if DataBase has named table.
		
		Parameters
		----------
		table_name: string
		    Name of SQL table
		con: SQLAlchemy connectable(engine/connection) or sqlite3 DBAPI2 connection
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		flavor: {'sqlite', 'mysql'}, default 'sqlite'
		    The flavor of SQL to use. Ignored when using SQLAlchemy connectable.
		    'mysql' is deprecated and will be removed in future versions, but it
		    will be further supported through SQLAlchemy connectables.
		schema : string, default None
		    Name of SQL schema in database to write to (if database flavor supports
		    this). If None, use default schema (default).
		
		Returns
		-------
		boolean
	**/
	static public function has_table(table_name:Dynamic, con:Dynamic, ?flavor:Dynamic, ?schema:Dynamic):Dynamic;
	/**
		Detect missing values (NaN in numeric arrays, None/NaN in object arrays)
		
		Parameters
		----------
		arr : ndarray or object value
		    Object to check for null-ness
		
		Returns
		-------
		isnulled : array-like of bool or bool
		    Array or bool indicating whether an object is null or if an array is
		    given which of the element is null.
		
		See also
		--------
		pandas.notnull: boolean inverse of pandas.isnull
	**/
	static public function isnull(obj:Dynamic):Dynamic;
	static public function lzip(?args:python.VarArgs<Dynamic>, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Convenience function to return the correct PandasSQL subclass based on the
		provided parameters
	**/
	static public function pandasSQL_builder(con:Dynamic, ?flavor:Dynamic, ?schema:Dynamic, ?meta:Dynamic, ?is_cursor:Dynamic):Dynamic;
	static public var print_function : Dynamic;
	/**
		Raise exception with existing traceback.
		If traceback is not passed, uses sys.exc_info() to get traceback.
	**/
	static public function raise_with_traceback(exc:Dynamic, ?traceback:Dynamic):Dynamic;
	/**
		DEPRECATED - use read_sql
		
		
		Read SQL query or database table into a DataFrame.
		
		Parameters
		----------
		sql : string SQL query or SQLAlchemy Selectable (select or text object)
		    to be executed, or database table name.
		con : SQLAlchemy connectable(engine/connection) or database string URI
		    or DBAPI2 connection (fallback mode)
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		index_col : string or list of strings, optional, default: None
		    Column(s) to set as index(MultiIndex)
		coerce_float : boolean, default True
		    Attempt to convert values to non-string, non-numeric objects (like
		    decimal.Decimal) to floating point, useful for SQL result sets
		params : list, tuple or dict, optional, default: None
		    List of parameters to pass to execute method.  The syntax used
		    to pass parameters is database driver dependent. Check your
		    database driver documentation for which of the five syntax styles,
		    described in PEP 249's paramstyle, is supported.
		    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}
		parse_dates : list or dict, default: None
		    - List of column names to parse as dates
		    - Dict of ``{column_name: format string}`` where format string is
		      strftime compatible in case of parsing string times or is one of
		      (D, s, ns, ms, us) in case of parsing integer timestamps
		    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
		      to the keyword arguments of :func:`pandas.to_datetime`
		      Especially useful with databases without native Datetime support,
		      such as SQLite
		columns : list, default: None
		    List of column names to select from sql table (only used when reading
		    a table).
		chunksize : int, default None
		    If specified, return an iterator where `chunksize` is the
		    number of rows to include in each chunk.
		
		Returns
		-------
		DataFrame
		
		Notes
		-----
		This function is a convenience wrapper around ``read_sql_table`` and
		``read_sql_query`` (and for backward compatibility) and will delegate
		to the specific function depending on the provided input (database
		table name or sql query).  The delegated function might have more specific
		notes about their functionality not listed here.
		
		See also
		--------
		read_sql_table : Read SQL database table into a DataFrame
		read_sql_query : Read SQL query into a DataFrame
	**/
	static public function read_frame(?args:python.VarArgs<Dynamic>, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Read SQL query or database table into a DataFrame.
		
		Parameters
		----------
		sql : string SQL query or SQLAlchemy Selectable (select or text object)
		    to be executed, or database table name.
		con : SQLAlchemy connectable(engine/connection) or database string URI
		    or DBAPI2 connection (fallback mode)
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		index_col : string or list of strings, optional, default: None
		    Column(s) to set as index(MultiIndex)
		coerce_float : boolean, default True
		    Attempt to convert values to non-string, non-numeric objects (like
		    decimal.Decimal) to floating point, useful for SQL result sets
		params : list, tuple or dict, optional, default: None
		    List of parameters to pass to execute method.  The syntax used
		    to pass parameters is database driver dependent. Check your
		    database driver documentation for which of the five syntax styles,
		    described in PEP 249's paramstyle, is supported.
		    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}
		parse_dates : list or dict, default: None
		    - List of column names to parse as dates
		    - Dict of ``{column_name: format string}`` where format string is
		      strftime compatible in case of parsing string times or is one of
		      (D, s, ns, ms, us) in case of parsing integer timestamps
		    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
		      to the keyword arguments of :func:`pandas.to_datetime`
		      Especially useful with databases without native Datetime support,
		      such as SQLite
		columns : list, default: None
		    List of column names to select from sql table (only used when reading
		    a table).
		chunksize : int, default None
		    If specified, return an iterator where `chunksize` is the
		    number of rows to include in each chunk.
		
		Returns
		-------
		DataFrame
		
		Notes
		-----
		This function is a convenience wrapper around ``read_sql_table`` and
		``read_sql_query`` (and for backward compatibility) and will delegate
		to the specific function depending on the provided input (database
		table name or sql query).  The delegated function might have more specific
		notes about their functionality not listed here.
		
		See also
		--------
		read_sql_table : Read SQL database table into a DataFrame
		read_sql_query : Read SQL query into a DataFrame
	**/
	static public function read_sql(sql:Dynamic, con:Dynamic, ?index_col:Dynamic, ?coerce_float:Dynamic, ?params:Dynamic, ?parse_dates:Dynamic, ?columns:Dynamic, ?chunksize:Dynamic):Dynamic;
	/**
		Read SQL query into a DataFrame.
		
		Returns a DataFrame corresponding to the result set of the query
		string. Optionally provide an `index_col` parameter to use one of the
		columns as the index, otherwise default integer index will be used.
		
		Parameters
		----------
		sql : string SQL query or SQLAlchemy Selectable (select or text object)
		    to be executed.
		con : SQLAlchemy connectable(engine/connection) or database string URI
		    or sqlite3 DBAPI2 connection
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		index_col : string or list of strings, optional, default: None
		    Column(s) to set as index(MultiIndex)
		coerce_float : boolean, default True
		    Attempt to convert values to non-string, non-numeric objects (like
		    decimal.Decimal) to floating point, useful for SQL result sets
		params : list, tuple or dict, optional, default: None
		    List of parameters to pass to execute method.  The syntax used
		    to pass parameters is database driver dependent. Check your
		    database driver documentation for which of the five syntax styles,
		    described in PEP 249's paramstyle, is supported.
		    Eg. for psycopg2, uses %(name)s so use params={'name' : 'value'}
		parse_dates : list or dict, default: None
		    - List of column names to parse as dates
		    - Dict of ``{column_name: format string}`` where format string is
		      strftime compatible in case of parsing string times or is one of
		      (D, s, ns, ms, us) in case of parsing integer timestamps
		    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
		      to the keyword arguments of :func:`pandas.to_datetime`
		      Especially useful with databases without native Datetime support,
		      such as SQLite
		chunksize : int, default None
		    If specified, return an iterator where `chunksize` is the number of
		    rows to include in each chunk.
		
		Returns
		-------
		DataFrame
		
		Notes
		-----
		Any datetime values with time zone information parsed via the `parse_dates`
		parameter will be converted to UTC
		
		See also
		--------
		read_sql_table : Read SQL database table into a DataFrame
		read_sql
	**/
	static public function read_sql_query(sql:Dynamic, con:Dynamic, ?index_col:Dynamic, ?coerce_float:Dynamic, ?params:Dynamic, ?parse_dates:Dynamic, ?chunksize:Dynamic):Dynamic;
	/**
		Read SQL database table into a DataFrame.
		
		Given a table name and an SQLAlchemy connectable, returns a DataFrame.
		This function does not support DBAPI connections.
		
		Parameters
		----------
		table_name : string
		    Name of SQL table in database
		con : SQLAlchemy connectable (or database string URI)
		    Sqlite DBAPI connection mode not supported
		schema : string, default None
		    Name of SQL schema in database to query (if database flavor
		    supports this). If None, use default schema (default).
		index_col : string or list of strings, optional, default: None
		    Column(s) to set as index(MultiIndex)
		coerce_float : boolean, default True
		    Attempt to convert values to non-string, non-numeric objects (like
		    decimal.Decimal) to floating point. Can result in loss of Precision.
		parse_dates : list or dict, default: None
		    - List of column names to parse as dates
		    - Dict of ``{column_name: format string}`` where format string is
		      strftime compatible in case of parsing string times or is one of
		      (D, s, ns, ms, us) in case of parsing integer timestamps
		    - Dict of ``{column_name: arg dict}``, where the arg dict corresponds
		      to the keyword arguments of :func:`pandas.to_datetime`
		      Especially useful with databases without native Datetime support,
		      such as SQLite
		columns : list, default: None
		    List of column names to select from sql table
		chunksize : int, default None
		    If specified, return an iterator where `chunksize` is the number of
		    rows to include in each chunk.
		
		Returns
		-------
		DataFrame
		
		Notes
		-----
		Any datetime values with time zone information will be converted to UTC
		
		See also
		--------
		read_sql_query : Read SQL query into a DataFrame.
		read_sql
	**/
	static public function read_sql_table(table_name:Dynamic, con:Dynamic, ?schema:Dynamic, ?index_col:Dynamic, ?coerce_float:Dynamic, ?parse_dates:Dynamic, ?columns:Dynamic, ?chunksize:Dynamic):Dynamic;
	static public var string_types : Dynamic;
	/**
		Check if DataBase has named table.
		
		Parameters
		----------
		table_name: string
		    Name of SQL table
		con: SQLAlchemy connectable(engine/connection) or sqlite3 DBAPI2 connection
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		flavor: {'sqlite', 'mysql'}, default 'sqlite'
		    The flavor of SQL to use. Ignored when using SQLAlchemy connectable.
		    'mysql' is deprecated and will be removed in future versions, but it
		    will be further supported through SQLAlchemy connectables.
		schema : string, default None
		    Name of SQL schema in database to write to (if database flavor supports
		    this). If None, use default schema (default).
		
		Returns
		-------
		boolean
	**/
	static public function table_exists(table_name:Dynamic, con:Dynamic, ?flavor:Dynamic, ?schema:Dynamic):Dynamic;
	/**
		Convert argument to datetime.
		
		Parameters
		----------
		arg : string, datetime, array of strings (with possible NAs)
		errors : {'ignore', 'raise', 'coerce'}, default 'raise'
		    - If 'raise', then invalid parsing will raise an exception
		    - If 'coerce', then invalid parsing will be set as NaT
		    - If 'ignore', then invalid parsing will return the input
		dayfirst : boolean, default False
		    Specify a date parse order if `arg` is str or its list-likes.
		    If True, parses dates with the day first, eg 10/11/12 is parsed as 2012-11-10.
		    Warning: dayfirst=True is not strict, but will prefer to parse
		    with day first (this is a known bug, based on dateutil behavior).
		yearfirst : boolean, default False
		    Specify a date parse order if `arg` is str or its list-likes.
		    - If True parses dates with the year first, eg 10/11/12 is parsed as 2010-11-12.
		    - If both dayfirst and yearfirst are True, yearfirst is preceded (same as dateutil).
		    Warning: yearfirst=True is not strict, but will prefer to parse
		    with year first (this is a known bug, based on dateutil beahavior).
		
		    .. versionadded: 0.16.1
		
		utc : boolean, default None
		    Return UTC DatetimeIndex if True (converting any tz-aware
		    datetime.datetime objects as well).
		box : boolean, default True
		    - If True returns a DatetimeIndex
		    - If False returns ndarray of values.
		format : string, default None
		    strftime to parse time, eg "%d/%m/%Y", note that "%f" will parse
		    all the way up to nanoseconds.
		exact : boolean, True by default
		    - If True, require an exact format match.
		    - If False, allow the format to match anywhere in the target string.
		unit : unit of the arg (D,s,ms,us,ns) denote the unit in epoch
		    (e.g. a unix timestamp), which is an integer/float number.
		infer_datetime_format : boolean, default False
		    If no `format` is given, try to infer the format based on the first
		    datetime string. Provides a large speed-up in many cases.
		
		Returns
		-------
		ret : datetime if parsing succeeded.
		    Return type depends on input:
		
		    - list-like: DatetimeIndex
		    - Series: Series of datetime64 dtype
		    - scalar: Timestamp
		
		    In case when it is not possible to return designated types (e.g. when
		    any element of input is before Timestamp.min or after Timestamp.max)
		    return will have datetime.datetime type (or correspoding array/Series).
		
		Examples
		--------
		Take separate series and convert to datetime
		
		>>> import pandas as pd
		>>> i = pd.date_range('20000101',periods=100)
		>>> df = pd.DataFrame(dict(year = i.year, month = i.month, day = i.day))
		>>> pd.to_datetime(df.year*10000 + df.month*100 + df.day, format='%Y%m%d')
		0    2000-01-01
		1    2000-01-02
		...
		98   2000-04-08
		99   2000-04-09
		Length: 100, dtype: datetime64[ns]
		
		Or from strings
		
		>>> df = df.astype(str)
		>>> pd.to_datetime(df.day + df.month + df.year, format="%d%m%Y")
		0    2000-01-01
		1    2000-01-02
		...
		98   2000-04-08
		99   2000-04-09
		Length: 100, dtype: datetime64[ns]
		
		Date that does not meet timestamp limitations:
		
		>>> pd.to_datetime('13000101', format='%Y%m%d')
		datetime.datetime(1300, 1, 1, 0, 0)
		>>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')
		NaT
	**/
	static public function to_datetime(arg:Dynamic, ?errors:Dynamic, ?dayfirst:Dynamic, ?yearfirst:Dynamic, ?utc:Dynamic, ?box:Dynamic, ?format:Dynamic, ?exact:Dynamic, ?coerce:Dynamic, ?unit:Dynamic, ?infer_datetime_format:Dynamic):Dynamic;
	/**
		Write records stored in a DataFrame to a SQL database.
		
		Parameters
		----------
		frame : DataFrame
		name : string
		    Name of SQL table
		con : SQLAlchemy connectable(engine/connection) or database string URI
		    or sqlite3 DBAPI2 connection
		    Using SQLAlchemy makes it possible to use any DB supported by that
		    library.
		    If a DBAPI2 object, only sqlite3 is supported.
		flavor : {'sqlite', 'mysql'}, default 'sqlite'
		    The flavor of SQL to use. Ignored when using SQLAlchemy connectable.
		    'mysql' is deprecated and will be removed in future versions, but it
		    will be further supported through SQLAlchemy connectables.
		schema : string, default None
		    Name of SQL schema in database to write to (if database flavor
		    supports this). If None, use default schema (default).
		if_exists : {'fail', 'replace', 'append'}, default 'fail'
		    - fail: If table exists, do nothing.
		    - replace: If table exists, drop it, recreate it, and insert data.
		    - append: If table exists, insert data. Create if does not exist.
		index : boolean, default True
		    Write DataFrame index as a column
		index_label : string or sequence, default None
		    Column label for index column(s). If None is given (default) and
		    `index` is True, then the index names are used.
		    A sequence should be given if the DataFrame uses MultiIndex.
		chunksize : int, default None
		    If not None, then rows will be written in batches of this size at a
		    time.  If None, all rows will be written at once.
		dtype : dict of column name to SQL type, default None
		    Optional specifying the datatype for columns. The SQL type should
		    be a SQLAlchemy type, or a string for sqlite3 fallback connection.
	**/
	static public function to_sql(frame:Dynamic, name:Dynamic, con:Dynamic, ?flavor:Dynamic, ?schema:Dynamic, ?if_exists:Dynamic, ?index:Dynamic, ?index_label:Dynamic, ?chunksize:Dynamic, ?dtype:Dynamic):Dynamic;
	/**
		DEPRECATED. Returns list of tuples corresponding to each row in given sql
		query.
		
		If only one column selected, then plain list is returned.
		
		To obtain the same result in the future, you can use the following:
		
		>>> execute(sql, con, params).fetchall()
		
		Parameters
		----------
		sql: string
		    SQL query to be executed
		con: DBAPI2 connection, default: None
		cur: deprecated, cursor is obtained from connection, default: None
		retry: boolean value to specify whether to retry after failure, default: True
		
		Returns
		-------
		Results Iterable
	**/
	static public function tquery(sql:Dynamic, ?con:Dynamic, ?cur:Dynamic, ?retry:Dynamic):Dynamic;
	/**
		DEPRECATED. Does the same thing as tquery, but instead of returning
		results, it returns the number of rows affected.  Good for update queries.
		
		To obtain the same result in the future, you can use the following:
		
		>>> execute(sql, con).rowcount
		
		Parameters
		----------
		sql: string
		    SQL query to be executed
		con: DBAPI2 connection, default: None
		cur: deprecated, cursor is obtained from connection, default: None
		retry: boolean value to specify whether to retry after failure, default: True
		params: list or tuple, optional, default: None
		    List of parameters to pass to execute method.
		
		Returns
		-------
		Number of affected rows
	**/
	static public function uquery(sql:Dynamic, ?con:Dynamic, ?cur:Dynamic, ?retry:Dynamic, ?params:Dynamic):Dynamic;
	/**
		DEPRECATED - use to_sql
		
		Write records stored in a DataFrame to a SQL database.
		
		Parameters
		----------
		frame : DataFrame
		name : string
		con : DBAPI2 connection
		flavor : {'sqlite', 'mysql'}, default 'sqlite'
		    The flavor of SQL to use.
		if_exists : {'fail', 'replace', 'append'}, default 'fail'
		    - fail: If table exists, do nothing.
		    - replace: If table exists, drop it, recreate it, and insert data.
		    - append: If table exists, insert data. Create if does not exist.
		index : boolean, default False
		    Write DataFrame index as a column
		
		Notes
		-----
		This function is deprecated in favor of ``to_sql``. There are however
		two differences:
		
		- With ``to_sql`` the index is written to the sql database by default. To
		  keep the behaviour this function you need to specify ``index=False``.
		- The new ``to_sql`` function supports sqlalchemy connectables to work
		  with different sql flavors.
		
		See also
		--------
		pandas.DataFrame.to_sql
	**/
	static public function write_frame(frame:Dynamic, name:Dynamic, con:Dynamic, ?flavor:Dynamic, ?if_exists:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
}